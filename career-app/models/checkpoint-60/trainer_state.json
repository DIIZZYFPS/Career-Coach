{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5393258426966292,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008988764044943821,
      "grad_norm": 5.867729663848877,
      "learning_rate": 0.0,
      "loss": 2.9327,
      "step": 1
    },
    {
      "epoch": 0.017977528089887642,
      "grad_norm": 6.090183734893799,
      "learning_rate": 4e-05,
      "loss": 2.8975,
      "step": 2
    },
    {
      "epoch": 0.02696629213483146,
      "grad_norm": 5.624568462371826,
      "learning_rate": 8e-05,
      "loss": 2.8868,
      "step": 3
    },
    {
      "epoch": 0.035955056179775284,
      "grad_norm": 3.8754143714904785,
      "learning_rate": 0.00012,
      "loss": 2.4527,
      "step": 4
    },
    {
      "epoch": 0.0449438202247191,
      "grad_norm": 2.0161869525909424,
      "learning_rate": 0.00016,
      "loss": 2.0694,
      "step": 5
    },
    {
      "epoch": 0.05393258426966292,
      "grad_norm": 1.3031994104385376,
      "learning_rate": 0.0002,
      "loss": 1.8915,
      "step": 6
    },
    {
      "epoch": 0.06292134831460675,
      "grad_norm": 0.925993800163269,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.6172,
      "step": 7
    },
    {
      "epoch": 0.07191011235955057,
      "grad_norm": 0.9641769528388977,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.6716,
      "step": 8
    },
    {
      "epoch": 0.08089887640449438,
      "grad_norm": 0.8304848074913025,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.5442,
      "step": 9
    },
    {
      "epoch": 0.0898876404494382,
      "grad_norm": 0.770542323589325,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.4786,
      "step": 10
    },
    {
      "epoch": 0.09887640449438202,
      "grad_norm": 0.7066054940223694,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.475,
      "step": 11
    },
    {
      "epoch": 0.10786516853932585,
      "grad_norm": 0.634419858455658,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.3018,
      "step": 12
    },
    {
      "epoch": 0.11685393258426967,
      "grad_norm": 0.5880578756332397,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.2255,
      "step": 13
    },
    {
      "epoch": 0.1258426966292135,
      "grad_norm": 0.5833691954612732,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.2159,
      "step": 14
    },
    {
      "epoch": 0.1348314606741573,
      "grad_norm": 0.4875255227088928,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.2615,
      "step": 15
    },
    {
      "epoch": 0.14382022471910114,
      "grad_norm": 0.49837127327919006,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.1379,
      "step": 16
    },
    {
      "epoch": 0.15280898876404495,
      "grad_norm": 0.5372047424316406,
      "learning_rate": 0.00016,
      "loss": 1.0898,
      "step": 17
    },
    {
      "epoch": 0.16179775280898875,
      "grad_norm": 0.4931901693344116,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.1087,
      "step": 18
    },
    {
      "epoch": 0.1707865168539326,
      "grad_norm": 0.5228118300437927,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.1082,
      "step": 19
    },
    {
      "epoch": 0.1797752808988764,
      "grad_norm": 0.5264540314674377,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.0743,
      "step": 20
    },
    {
      "epoch": 0.18876404494382024,
      "grad_norm": 0.47618839144706726,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.0771,
      "step": 21
    },
    {
      "epoch": 0.19775280898876405,
      "grad_norm": 0.42978352308273315,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.9219,
      "step": 22
    },
    {
      "epoch": 0.20674157303370785,
      "grad_norm": 0.4437331557273865,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.0656,
      "step": 23
    },
    {
      "epoch": 0.2157303370786517,
      "grad_norm": 0.42269206047058105,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.971,
      "step": 24
    },
    {
      "epoch": 0.2247191011235955,
      "grad_norm": 0.39767390489578247,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.9787,
      "step": 25
    },
    {
      "epoch": 0.23370786516853934,
      "grad_norm": 0.41702714562416077,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.9572,
      "step": 26
    },
    {
      "epoch": 0.24269662921348314,
      "grad_norm": 0.44193926453590393,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.035,
      "step": 27
    },
    {
      "epoch": 0.251685393258427,
      "grad_norm": 0.41142502427101135,
      "learning_rate": 0.00012,
      "loss": 0.9653,
      "step": 28
    },
    {
      "epoch": 0.2606741573033708,
      "grad_norm": 0.4586915969848633,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.0788,
      "step": 29
    },
    {
      "epoch": 0.2696629213483146,
      "grad_norm": 0.3814336955547333,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.0086,
      "step": 30
    },
    {
      "epoch": 0.2786516853932584,
      "grad_norm": 0.4156719148159027,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.9802,
      "step": 31
    },
    {
      "epoch": 0.2876404494382023,
      "grad_norm": 0.39644163846969604,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.9964,
      "step": 32
    },
    {
      "epoch": 0.2966292134831461,
      "grad_norm": 0.4045722484588623,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.9998,
      "step": 33
    },
    {
      "epoch": 0.3056179775280899,
      "grad_norm": 0.4123554527759552,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.9458,
      "step": 34
    },
    {
      "epoch": 0.3146067415730337,
      "grad_norm": 0.40258821845054626,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.9733,
      "step": 35
    },
    {
      "epoch": 0.3235955056179775,
      "grad_norm": 0.40742963552474976,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.9522,
      "step": 36
    },
    {
      "epoch": 0.3325842696629214,
      "grad_norm": 0.39478716254234314,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.9461,
      "step": 37
    },
    {
      "epoch": 0.3415730337078652,
      "grad_norm": 0.41441211104393005,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.9841,
      "step": 38
    },
    {
      "epoch": 0.350561797752809,
      "grad_norm": 0.4274226427078247,
      "learning_rate": 8e-05,
      "loss": 0.9542,
      "step": 39
    },
    {
      "epoch": 0.3595505617977528,
      "grad_norm": 0.38809531927108765,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.9586,
      "step": 40
    },
    {
      "epoch": 0.3685393258426966,
      "grad_norm": 0.4752553403377533,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.0045,
      "step": 41
    },
    {
      "epoch": 0.3775280898876405,
      "grad_norm": 0.4050235152244568,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.9612,
      "step": 42
    },
    {
      "epoch": 0.3865168539325843,
      "grad_norm": 0.4177931249141693,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.9054,
      "step": 43
    },
    {
      "epoch": 0.3955056179775281,
      "grad_norm": 0.43448707461357117,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.9348,
      "step": 44
    },
    {
      "epoch": 0.4044943820224719,
      "grad_norm": 0.3655422031879425,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.9179,
      "step": 45
    },
    {
      "epoch": 0.4134831460674157,
      "grad_norm": 0.39716216921806335,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.947,
      "step": 46
    },
    {
      "epoch": 0.42247191011235957,
      "grad_norm": 0.3849180340766907,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.9442,
      "step": 47
    },
    {
      "epoch": 0.4314606741573034,
      "grad_norm": 0.4053003191947937,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.0372,
      "step": 48
    },
    {
      "epoch": 0.4404494382022472,
      "grad_norm": 0.3881155252456665,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.9503,
      "step": 49
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 0.39245083928108215,
      "learning_rate": 4e-05,
      "loss": 0.9194,
      "step": 50
    },
    {
      "epoch": 0.4584269662921348,
      "grad_norm": 0.3804028630256653,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.8592,
      "step": 51
    },
    {
      "epoch": 0.46741573033707867,
      "grad_norm": 0.3876485228538513,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.9262,
      "step": 52
    },
    {
      "epoch": 0.4764044943820225,
      "grad_norm": 0.4184730052947998,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.9891,
      "step": 53
    },
    {
      "epoch": 0.4853932584269663,
      "grad_norm": 0.4075922667980194,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.952,
      "step": 54
    },
    {
      "epoch": 0.4943820224719101,
      "grad_norm": 0.3891400992870331,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.9495,
      "step": 55
    },
    {
      "epoch": 0.503370786516854,
      "grad_norm": 0.46721577644348145,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.9176,
      "step": 56
    },
    {
      "epoch": 0.5123595505617977,
      "grad_norm": 0.3956739604473114,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.9714,
      "step": 57
    },
    {
      "epoch": 0.5213483146067416,
      "grad_norm": 0.4246912896633148,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.016,
      "step": 58
    },
    {
      "epoch": 0.5303370786516854,
      "grad_norm": 0.4244120717048645,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.0301,
      "step": 59
    },
    {
      "epoch": 0.5393258426966292,
      "grad_norm": 0.42519378662109375,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.8735,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5112385721002560.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
